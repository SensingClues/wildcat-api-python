{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8694088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the functions\n",
    "from wildcatpy.api_calls import WildcatApi\n",
    "from wildcatpy.src.helper_functions import check_bounds\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32674ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataExtractor(\"test\")\n",
    "cleaner_file = test.get_extractor_json(\"track_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8eac58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'full_key': ['extracted', 'content', 0, 'headers'],\n",
       "  'all_columns': ['entityId', 'entityType', 'projectId', 'projectName'],\n",
       "  'explode_values': []},\n",
       " {'full_key': ['extracted', 'content', 1, 'GeoFeature'],\n",
       "  'all_columns': ['featureType', 'length', 'startWhen', 'endWhen'],\n",
       "  'explode_values': []},\n",
       " {'full_key': ['extracted', 'content', 1, 'GeoFeature', 'agent'],\n",
       "  'all_columns': ['agentName'],\n",
       "  'explode_values': []}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462f97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_values_to_extract(extractor, \n",
    "                           values_to_extract = None,\n",
    "                           full_key = None,\n",
    "                          ):\n",
    "    if values_to_extract == None:\n",
    "        values_to_extract = []\n",
    "    if full_key == None:\n",
    "        full_key = []\n",
    "    for key,value in extractor.items():\n",
    "        if key.isnumeric(): #check bc there can be integers\n",
    "            key = int(key)\n",
    "        if key == \"extract_values\":\n",
    "            values_to_extract.append({\"full_key\":full_key, \"all_columns\": value, \"explode_values\": []})\n",
    "        elif key == \"explode_values\":\n",
    "            values_to_extract.append({\"full_key\":full_key, \"all_columns\": [], \"explode_values\": value})\n",
    "\n",
    "        else:\n",
    "            new_key = full_key + [key]\n",
    "            values_to_extract.extend(find_values_to_extract(value,\n",
    "                                     full_key=new_key)\n",
    "                                    )\n",
    "    return values_to_extract\n",
    "\n",
    "def recurGet(d, ks): \n",
    "    head, *tail = ks \n",
    "    return recurGet(d[head], tail) if tail else d[head]\n",
    "\n",
    "class dataExtractor:\n",
    "    def __init__(self,\n",
    "                 input_data\n",
    "                ):\n",
    "        self.input_data = input_data\n",
    "        self.data = input_data\n",
    "        \n",
    "    def deeper_in_nested(self,keys):\n",
    "        self.data = recurGet(self.data,keys)\n",
    "    def select_columns(self,keep_cols):\n",
    "        self.data = [\n",
    "            {key:item} for row in self.data\\\n",
    "                       for key,item in row.items()\\\n",
    "                       if key in keep_cols\n",
    "                    ]       \n",
    "    def list_to_pd(self):\n",
    "        return pd.DataFrame(self.data)\n",
    "    def flatten_data(self):\n",
    "        self.data = sum(self.data, [])\n",
    "    def get_list_dict(self):\n",
    "        return self.data\n",
    "    def get_list_values(self):\n",
    "        return [[_ for _ in row.values()] for row in self.data]\n",
    "    def get_extractor_json(self, file_name):\n",
    "        with open(f\"wildcatpy/extractors/{file_name}.json\", \"r\") as f:\n",
    "            return find_values_to_extract(json.load(f))\n",
    "    def iterate_extractor(self,extractor_file_name):\n",
    "        new_data = []\n",
    "        for row in self.data:\n",
    "            new_data.append(self.extract_with_extractor(row,extractor_file_name))\n",
    "        self.data = new_data\n",
    "    def extract_with_extractor(self,\n",
    "                               data_for_extract,\n",
    "                               extractor_file_name\n",
    "                              ): \n",
    "        new_data = {}\n",
    "        additional = [{}]#if it isn't made in the extraction of exploding columns\n",
    "        for extract_val in self.get_extractor_json(extractor_file_name):\n",
    "            if len(extract_val[\"all_columns\"]) > 0:\n",
    "                full_key = extract_val[\"full_key\"]\n",
    "                all_columns = extract_val[\"all_columns\"]\n",
    "                data = recurGet(data_for_extract, full_key)\n",
    "                new_data = {**new_data, **{key:data[key] for key in all_columns}}\n",
    "        for extract_val in self.get_extractor_json(extractor_file_name):\n",
    "            if len(extract_val[\"explode_values\"]) > 0:\n",
    "                full_key = extract_val[\"full_key\"]\n",
    "                print(full_key)\n",
    "                data = recurGet(data_for_extract, full_key)\n",
    "                all_extr_columns = extract_val[\"explode_values\"]\n",
    "                if len(data) > 0:\n",
    "                    additional = [{col:row[col] for col in all_extr_columns} for row in data]\n",
    "        return [{**new_data, **add} for add in additional]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86738d",
   "metadata": {},
   "source": [
    "### 1.0 Login  (done)\n",
    "\n",
    "Needed before this step\n",
    "* \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd450583",
   "metadata": {},
   "outputs": [],
   "source": [
    "username= \"jobvancreij\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915f2b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WildcatApi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#store this api_call object\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#This is needed for future calls\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m api_call \u001b[38;5;241m=\u001b[39m \u001b[43mWildcatApi\u001b[49m(username,password)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WildcatApi' is not defined"
     ]
    }
   ],
   "source": [
    "#store this api_call object\n",
    "#This is needed for future calls\n",
    "api_call = WildcatApi(username,password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29815e9e",
   "metadata": {},
   "source": [
    "### 1.1: Get groups (done)\n",
    "\n",
    "Needed before this step\n",
    "* 1.1 Login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786cb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': {'dateTimeRange': {'from': '1900-01-01T00:00:00-00:00', 'to': '9999-12-31T23:59:59-00:00'}, 'entities': ['Observation', 'track']}, 'options': {'start': 1, 'pageLength': 0}}\n",
      "req to https://focus.sensingclues.org/api/search/all/facets success\n"
     ]
    }
   ],
   "source": [
    "info = api_call.get_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb71fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_groups in module wildcatpy.api_calls:\n",
      "\n",
      "get_groups() method of wildcatpy.api_calls.WildcatApi instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(api_call.get_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341e0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wildcatpy.src.cleaner.dataExtractor object at 0x10435b7c0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dataExtractor' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m cleaner \u001b[38;5;241m=\u001b[39m dataExtractor(info)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(info)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcleaner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroups_extractor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cleaner\u001b[38;5;241m.\u001b[39mselect_columns([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m cleaner\u001b[38;5;241m.\u001b[39mlist_to_pd()\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mdataExtractor.iterate_extractor\u001b[0;34m(self, extractor_file_name)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m,extractor_file_name):\n\u001b[1;32m     55\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m     57\u001b[0m         new_data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_with_extractor(row,extractor_file_name))\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m new_data\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dataExtractor' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cleaner = dataExtractor(info)\n",
    "print(info)\n",
    "cleaner.iterate_extractor(\"groups_extractor\")\n",
    "\n",
    "cleaner.select_columns([\"name\"])\n",
    "df = cleaner.list_to_pd()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd058a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dataExtractor' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mcleaner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_list_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m groups \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(groups)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mdataExtractor.get_list_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_list_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mvalues()] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dataExtractor' object is not iterable"
     ]
    }
   ],
   "source": [
    "info = cleaner.get_list_values()\n",
    "groups = info[0]\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd16aeb",
   "metadata": {},
   "source": [
    "### 1.2: get-observations\n",
    "Needed before this step\n",
    "* 1.1 Login\n",
    "* 1.2 Get groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3706c8",
   "metadata": {},
   "source": [
    "### 1.3: get-track-metadata\n",
    "Needed before this step\n",
    "* 1.1 Login\n",
    "* 1.2 Get groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8148d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "/var/folders/ym/vg2hn__n4h55zb6g8m66zg7w0000gn/T/ipykernel_10819/1256664948.py:11: SyntaxWarning: list indices must be integers or slices, not str; perhaps you missed a comma?\n",
      "  ([\"filters\"][\"geoQuery\"][\"mapBounds\"])\n"
     ]
    }
   ],
   "source": [
    "def make_query(bounds=None,\n",
    "               operator = None,\n",
    "               timerange=None,\n",
    "               type_analysis=None,\n",
    "               groups=None,\n",
    "               page_info=None,\n",
    "               end_time = \"T23:59:59-00:00\", #if someone has to make very specific calls change this\n",
    "               start_time = \"T00:00:00-00:00\"\n",
    "              ):\n",
    "    output = { \n",
    "        ([\"filters\"][\"geoQuery\"][\"mapBounds\"])\n",
    "    \n",
    "    }\n",
    "    query_object = {\"filters\": {\"geoQuery\": {} }}\n",
    "    if bounds != None:\n",
    "        query_object[\"filters\"][\"geoQuery\"][\"mapBounds\"] = bounds\n",
    "    if operator != None:\n",
    "        query_object[\"filters\"][\"geoQuery\"][\"operator\"] = operator\n",
    "    if timerange != None:\n",
    "        query_object[\"filters\"][\"dateTimeRange\"] = { \n",
    "                     \"to\": f\"{timerange[1]}{end_time}\", #\"2009-10-10T12:00:00-05:00\",\n",
    "                      \"from\": f\"{timerange[1]}{start_time}\"\n",
    "                      }\n",
    "    if type_analysis != None:\n",
    "        query_object[\"filters\"][\"entities\"] = type_analysis\n",
    "\n",
    "    if groups != None:\n",
    "        query_object[\"filters\"][\"dataSources\"] = groups\n",
    "    if page_info != None:\n",
    "        query_object[\"options\"] = {\n",
    "            \"start\": page_info[0],\n",
    "             \"page_length\": page_info[1]\n",
    "        }\n",
    "        \n",
    "    return query_object\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23fed504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"a\"]\n",
    "test.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec8b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nested_dict(output_prep,\n",
    "                     output_dict = None,\n",
    "                    ):\n",
    "    if output_dict == None:\n",
    "        output_dict = {} \n",
    "    for prep in output_prep:\n",
    "        keys = prep[1]\n",
    "        values = prep[0]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "356f4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nested_dict(value, \n",
    "                     keys,\n",
    "                     output_dict = None,\n",
    "                    ):\n",
    "    if output_dict == None:\n",
    "        output_dict = {}\n",
    "    key = keys.pop(0)\n",
    "    if (len(keys) > 0 and output_dict.get(key, False)): #if more then one key and dict key exists\n",
    "        output_dict[key] = make_nested_dict(value, keys,output_dict[key])\n",
    "    elif (len(keys) > 0 and not  output_dict.get(key, False)):#if more then one key and dict key doesn't exist   \n",
    "        output_dict[key] = make_nested_dict(value, keys,{})     \n",
    "    else: #if only 1 key left finalize the dict\n",
    "        output_dict[key] = value\n",
    "    return output_dict\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(bounds=None,\n",
    "               operator = None,\n",
    "               date_from=None,\n",
    "               date_to=None,\n",
    "               type_analysis=None,\n",
    "               groups=None,\n",
    "               page_nbr=None,\n",
    "               page_length=None,\n",
    "               end_time = \"T23:59:59-00:00\", #if someone has to make very specific calls change this\n",
    "               start_time = \"T00:00:00-00:00\"\n",
    "              ):\n",
    "    page_nbr = None if (page_nbr == None or page_length == None) else page_nbr* page_length +1\n",
    "    time_from = None if date_from == None else f\"{date_from}{start_time}\" #add date and time \n",
    "    time_to = None if date_to == None else f\"{date_to}{end_time}\" #add date and time \n",
    "\n",
    "    # shows the value and where it should be placed in the dictionary\n",
    "    # For new vars just add (<varname, [<cols><in><final><dict>])\n",
    "    output_prep = [\n",
    "        (bounds, [\"filters\",\"geoQuery\",\"mapBounds\"]),\n",
    "        (operator, [\"filters\", \"geoQuery\", \"operator\"]),\n",
    "        (time_from, [\"filters\", \"dateTimeRange\", \"from\"]),\n",
    "        (time_to, [\"filters\", \"dateTimeRange\", \"to\"]),\n",
    "        (type_analysis, [\"filters\", \"entities\"]),\n",
    "        (groups, [\"filters\", \"dataSources\"]),\n",
    "        (page_nbr , [\"options\", \"start\"]),\n",
    "        (page_length, [\"options\", \"page_length\"]),   \n",
    "    ]\n",
    "    \n",
    "    final_output = [_ for _ in output_prep if _[0] != None] #only return non None vars\n",
    "    #convert output_prep to query \n",
    "    query = make_nested_dict(*final_output[0]) #init query with first row (no output_dict yet)\n",
    "    for row in final_output[1:]: \n",
    "        query = make_nested_dict(*row,query)#loop for the rest, send output dict so it is updated \n",
    "    return query\n",
    "               \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8982db",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = make_query( time_from = \"2020-01-1\",\n",
    "           time_to = \"2022-12-31\",\n",
    "           type_analysis = [\"Observation\", \"track\"],\n",
    "           page_nbr=1,\n",
    "           page_length=0\n",
    "          )\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def make_query(bounds,to_date,from_date,type_analysis,groups,page_nbr,_page_length):\n",
    "    return  {\n",
    "            \"filters\":\n",
    "              {\n",
    "                  \"geoQuery\":\n",
    "                    {\n",
    "                        \"operator\":\"intersects\",\n",
    "                        \"mapBounds\":bounds,\n",
    "                          \"drawings\":[]\n",
    "                          },\n",
    "                  \"dateTimeRange\":\n",
    "                  {\n",
    "                      \"to\": f\"{to_date}T12:24:00-00:00\", #\"2009-10-10T12:00:00-05:00\",\n",
    "                      \"from\": f\"{from_date}T00:00:00-00:00\"\n",
    "                  },\n",
    "                  \"entities\":[type_analysis],\n",
    "                  \"dataSources\": groups,\n",
    "              },\n",
    "          \"options\": {\n",
    "              \"start\": page_nbr*_page_length+1,\n",
    "              \"pageLength\": _page_length\n",
    "          }\n",
    "        }\n",
    "    \n",
    "\n",
    "class Test(WildcatApi):\n",
    "    def _init(self):\n",
    "        pass\n",
    "    def track_extractor( self,\n",
    "        groups,\n",
    "        bounds = {\"north\":90,\"east\": 180,\"west\": -179,\"south\": -89},\n",
    "        from_date = \"1900-01-01\",\n",
    "        to_date = \"9999-12-31\",\n",
    "        updateProgress = None\n",
    "    ):\n",
    "        return(self.general_api_test(groups,\n",
    "                            \"track\",\n",
    "                            \"track_extractor\",  \n",
    "                            bounds,\n",
    "                            from_date,\n",
    "                            to_date,\n",
    "                            updateProgress\n",
    "                           ))\n",
    "    def observation_extractor( self,\n",
    "        groups,\n",
    "        bounds = {\"north\":90,\"east\": 180,\"west\": -179,\"south\": -89},\n",
    "        from_date = \"1900-01-01\",\n",
    "        to_date = \"9999-12-31\",\n",
    "        updateProgress = None\n",
    "    ):\n",
    "        df = self.general_api_test(groups,\n",
    "                            \"observation\",\n",
    "                            \"observation_extractor\",  \n",
    "                            bounds,\n",
    "                            from_date,\n",
    "                            to_date,\n",
    "                            updateProgress\n",
    "                           )\n",
    "        # fix filter for the concepts\n",
    "        # transform concept id\n",
    "        return df\n",
    "    \n",
    "    def general_api_test(\n",
    "        self,\n",
    "        groups,\n",
    "        type_analysis,\n",
    "        extractor_name,\n",
    "        bounds = {\"north\":90,\"east\": 180,\"west\": -179,\"south\": -89},\n",
    "        from_date = \"1900-01-01\",\n",
    "        to_date = \"9999-12-31\",\n",
    "        updateProgress = None,\n",
    "        _page_length = 10\n",
    "\n",
    "\n",
    "    ):\n",
    "        output_data = []       \n",
    "        extra_request = True\n",
    "        first_iter = True\n",
    "        page_nbr = 0     \n",
    "        #fix timestamp!! \n",
    "        while extra_request:\n",
    "            query = make_query(bounds,to_date,from_date,type_analysis,groups,page_nbr,_page_length)\n",
    "            r = self.api_call(\"post\",\"search/all/results\", query)\n",
    "            if first_iter:\n",
    "                nbr_pages = math.ceil(r.json()[\"total\"]/_page_length)\n",
    "                if nbr_pages == 0:\n",
    "                    break\n",
    "            cleaner = dataExtractor(r.json())\n",
    "            cleaner.deeper_in_nested([\"results\"])\n",
    "            cleaner.iterate_extractor(extractor_name)\n",
    "            cleaner.flatten_data()\n",
    "            output_data.extend(cleaner.get_list_dict())\n",
    "            if page_nbr == nbr_pages:\n",
    "                break\n",
    "            page_nbr +=1\n",
    "        return pd.DataFrame(output_data)\n",
    "            \n",
    "      \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d10397",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Test(username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x.track_extractor(groups,\n",
    "        bounds = {\"north\":90,\"east\": 180,\"west\": -179,\"south\": -89},\n",
    "        from_date = \"2022-01-01\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aa1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x.general_api_test(groups,\"Observation\",\"observation_extractor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99da98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f61b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a=1,b=2,c=10,types=None):\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(types)\n",
    "    \n",
    "def testb(**args):\n",
    "    test(**args,types = \"hao\")\n",
    "    \n",
    "testb(a=5,b=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1540562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32772e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
